{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd79c32-d0be-45c0-a251-93f82125386b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# AI Lab: Computer Vision and NLP\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e04e5f0-b7ff-4c9e-b115-b11c7fef1c65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Course Outline (Tentative)\n",
    "\n",
    "- Introduction to Image Processing\n",
    "- Introduction to Image Processing Tools\n",
    "- Machine/Deep Learning Recap\n",
    "- Introduction to Machine Learning Tools\n",
    "- Introduction to Computer Vision\n",
    "- Introduction to Computer Vision/Deep Learning Tool\n",
    "- Introduction to NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd81f438-f7dc-4fb5-9b94-5e8eb47cde4f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## About Me\n",
    "<img src=\"imgs/1.jpg\" width=400>\n",
    "\n",
    "Department of Computer Science, Via Salaria 113\n",
    "\n",
    "### Computer Vision Laboratory (VisionLab)\n",
    "- Prof. Luigi Cinque, Director\n",
    "- Prof. Danilo Avola, Co-Director\n",
    "- Daniele Pannone (me), R&D Supervisor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a02e00a-74b6-460e-ac6f-88c794a46276",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## How to Find Us\n",
    "\n",
    "From Termini Station:\n",
    "- Busses no. 38, 92, 223, 360\n",
    "- Piazza Fiume Stop\n",
    "- 200 meters by walking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a4e7f2-e6ac-4777-8b71-487402e7bc4f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Course Information\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/qr_website.png\" width=400> </td>\n",
    "        <td> <img src=\"imgs/qr_classroom.png\" width=400> </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94b832e-fee0-4b87-9e1d-5415cb61f582",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Appointments\n",
    "\n",
    "Email me at daniele.pannone@uniroma1.it, and we will organize a gmeet!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c756fe-a6c4-43ce-bf3f-5dafdccd8cce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## More on the Course\n",
    "\n",
    "- Course Material: just these slides!\n",
    "- Mainly practical\n",
    "- Exam: Probably a group (from 2 to 4 students, better 3) project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7212c-fc4c-41fd-b320-9aad94846442",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Stuff for Programming\n",
    "\n",
    "- Language: Python (recomended installation: Anaconda)\n",
    "- Image Processing Framework: OpenCV\n",
    "- Machine Learning Framework: Scikit Learn\n",
    "- Deep Learning Framework: Pytorch\n",
    "- Jupyter Notebook (???)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1bf638-bdb7-435a-a737-da4715263c71",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Anaconda Installation\n",
    "Download the installer from https://www.anaconda.com/products/individual and follow the instructions.\n",
    "\n",
    "### OpenCV Installation\n",
    "Through pip:\n",
    "```pip install opencv-contrib-python```\n",
    "\n",
    "### Scikit-learn\n",
    "Through pip:\n",
    "```pip install scikit-learn```\n",
    "\n",
    "### Pytorch\n",
    "We will see this later, but it is intalled with ```pip``` too!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96e8bd7-318a-4b4d-bf9e-ee5d1aa0918e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Let's Begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbf2947-dbc2-4ff4-897a-c7ce55463a66",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Aim of the Course\n",
    "\n",
    "Understand what do you need to solve a Computer Vision or NLP problem, and design or use the solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d56962-afbf-4e11-99f0-8378b9e0f6eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### So what is Computer Vision?\n",
    "\n",
    "If we really need to provide a definition, Computer Vision (CV) is that branch of Computer Science that tries to emulate the human visual system, aiming to understand the content of a scene."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cc623e-1059-45b8-923f-30717756592e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/2_1.jpg\" width=400> </td>\n",
    "        <td> <img src=\"imgs/2_2.jpg\" width=530> </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> What humans see </td>\n",
    "        <td> What machines see </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14f26ce-c2dd-4fdf-afa1-1000e3667724",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"imgs/2_3.jpg\" width=530>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd63b576-c518-42e5-8e37-0b2902ef18e9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### So, can computers match human perception?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0bff6d-a939-4626-bd49-eb0d31fcab8d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Answer: So and So\n",
    "\n",
    "- Computers are better at \"easy\" things, and human are better at \"hard\" things.\n",
    "- Deep Learning accelerated the progress in the last years\n",
    "- What is considered \"hard\" is constantly changing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6471a195-54c6-426f-b3bc-5978f3040d01",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Human perception can be easily fooled\n",
    "\n",
    "<img src=\"imgs/3.jpg\" width=300> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba793b72-b3ad-494f-b4d4-111f908c2a71",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "But humans can extract a lot of information from a \"little data\"\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/4_1.jpg\" width=400> </td>\n",
    "        <td> <img src=\"imgs/4_2.jpg\" width=520> </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71b5ee-0681-412b-85a4-760eaa554490",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "The goal of Computer Vision part 1\n",
    "\n",
    "<img src=\"imgs/5.jpg\" width=600> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b7e757-c730-49f4-8b3d-bc2a0d2fd6c3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "The goal of Computer Vision part 2\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/QkcU0gwZUdg\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3109f970-32a7-4524-b193-c4f967a5e2e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Why Study Computer Vision\n",
    "\n",
    "Nowaday, CV is used in a HUGE set of real life applications.\n",
    "\n",
    "Here are some examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f94680-8a74-40e3-a960-68a4c45ce2c1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Photogrammetry\n",
    "<img src=\"imgs/6.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd5653-997b-4640-bdfd-7567ca8a5d37",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Object Detection\n",
    "<img src=\"imgs/7.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f38fdf-9979-4da5-a177-1d93c26b3211",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Image Enhancement\n",
    "<img src=\"imgs/8.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350db441-244a-483c-ae75-d36276370028",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Image Restoration\n",
    "<img src=\"imgs/0_3.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc60f2e-8d8c-415c-ae46-f37055f61ba6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Image Denoising\n",
    "<img src=\"imgs/8_2.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99990f5-2b60-4c4d-bc91-b471bdfc3c7b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Forensic\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/9_1.jpg\" width=400> </td>\n",
    "        <td> <img src=\"imgs/9_2.jpg\" width=275> </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b8abb0-6ecf-4104-a145-f79bf03112f8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Optical Character Recognition (OCR)\n",
    "<img src=\"imgs/10.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e414eb34-c0f6-4c0e-b9e6-9f93a13c3914",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Face Detection\n",
    "<img src=\"imgs/11.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fe3081-f96d-437b-ab16-8d0680f12a7c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Vision-Based Biometrics\n",
    "\n",
    "<img src=\"imgs/12.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d0e793-1a7a-4f5f-96b3-3026ea387a0f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "She has been recognized through the iris!\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/13.jpg\" width=400> </td>\n",
    "        <td> <img src=\"imgs/13_1.jpg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/13_2.jpg\" width=300> </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78df0672-b4fa-44db-bd0a-f1d34668dfc9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Special Effects:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/15_1.jpg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/15_2.jpg\" width=300> </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b51476-c990-4602-8ef6-80561d6c398e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Face Tracking\n",
    "<img src=\"imgs/16.jpg\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a61a47-d7e2-4e1a-9730-81b882001b7b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Image Synthesis\n",
    "<img src=\"imgs/17.jpg\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c959d6c6-2e49-4114-b58b-06addd77cde0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Content Generation\n",
    "<img src=\"imgs/17_2.jpg\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab5b62-7eb1-4478-9476-11db64c89307",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Self-Driving Cars\n",
    "<video controls src='imgs/self_driving.mp4' height=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d51b1-b5bc-4f2d-bbdc-ae387c7fc470",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Augmented and Virtual Reality\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/19_1.jpg\" width=400> </td>\n",
    "        <td> <img src=\"imgs/19_2.jpg\" width=400> </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d538774-71fe-40f7-bd76-97e3d0d5bcb0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Medical Imaging\n",
    "<img src=\"imgs/20.jpg\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b93239-de83-4b81-8665-a7e03a39532b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Computer Vision in Sports\n",
    "<img src=\"imgs/tennis.jpg\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4af9f1-9544-4ee4-ad2f-53020cad4787",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Which are the Computer Vision Problems?\n",
    "### Different viewpoint\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/21_1.jpg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/21_2.jpg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/21_3.jpg\" width=300> </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4433e9b9-15d5-4af5-970e-00bc33975798",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Different Illumination\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/22_1.jpg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/22_2.jpg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/22_3.jpg\" width=300> </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09534f0-9422-45a1-83ce-e26dcf4538f6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Intra-class Variation\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/23_1.jpg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/23_2.jpg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/23_3.jpg\" width=300> </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a138f411-ffeb-43e8-a9bf-57d5ba9ff735",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Background Clutter\n",
    "<img src=\"imgs/24.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1168db8-bb3e-4034-9323-d5330b34b42c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Occlusions\n",
    "<img src=\"imgs/25.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a733b81-be53-4dbd-bf4c-71c9546c6ce0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Challenges\n",
    "### Ambiguity\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/26_1.jpg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/26_2.jpg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/26_3.jpg\" width=300> </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60650de-62cf-4ade-a76f-560b3e83be75",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Scalability\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/27_1.jpg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/27_2.jpg\" width=300> </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962f3431-b830-4628-816a-ef48f34f860d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Usually, Computer Vision algorithms and techniques use images as input.\n",
    "\n",
    "## But how many types of images do we have?\n",
    "### Thermal Images\n",
    "<img src=\"imgs/28.jpeg\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8132755-8488-4f41-848c-041dff5d70fc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Multispectral Images\n",
    "<img src=\"imgs/29.jpg\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40afbe5-b2ee-4c96-b007-8e9a43405f4a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Depth Images\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/30_1.jpg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/30_2.jpeg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/30_3.jpg\" width=300> </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4ddbfb-d29f-410c-ac59-e27469220382",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Medical Images\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/31_1.jpg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/31_2.jpg\" width=500> </td>\n",
    "    </tr>\n",
    "    \n",
    "   <tr>\n",
    "       <td> RX Image </td>\n",
    "       <td> MRI Image </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128d1d02-27a3-4599-b164-d884dc019b2d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### RGB Images\n",
    "<img src=\"imgs/32.jpg\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981f610f-1e30-43a8-a17f-198567290c6e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Which device produce each image?\n",
    "## Thermal Cameras\n",
    "<img src=\"imgs/33.jpg\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7346e208-426c-485e-b8f0-f98383624932",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Multispectral Cameras\n",
    "<img src=\"imgs/34.jpg\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1d7ded-61a7-4671-810b-46019b98166e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Depth Cameras\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/35_1.jpg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/35_2.jpg\" width=300> </td>\n",
    "        <td> <img src=\"imgs/35_3.jpg\" width=150> </td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td> Stereo Camera </td>\n",
    "        <td> Side Scan Sonar </td>\n",
    "        <td> Ecography Machine </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2915e7-c1ba-4c9e-baeb-b9f02c1bfe01",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Medical Imaging Machine\n",
    "<img src=\"imgs/36.jpg\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebcb57c-bf3c-47eb-b892-0168b6ce3aa6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Everyday Cameras\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"imgs/37_1.jpg\" width=400> </td>\n",
    "        <td> <img src=\"imgs/37_2.jpg\" width=400> </td>\n",
    "    </tr>\n",
    "   \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37024f2e-0140-4cb5-a7d5-214cf52dd946",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "During this course, we mainly focus on the latter for the following reasons:\n",
    "\n",
    "- The majority of the dataset is comprised of standard RGB images\n",
    "- RGB images weight less\n",
    "- You can try your model with real cases!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852a94d0-f0fc-45de-b514-bf0158064a37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## How RGB Images Are Made\n",
    "Now we are going to see how the images that we use and see everyday are made. We will see the following concept at a very high level:\n",
    "\n",
    "- Light\n",
    "- Digital Cameras\n",
    "- Color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818c8c7b-9e64-4c1e-b416-3bf6eb6f3e0d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Light\n",
    "We are used to bring our device, take a picture, and watch the result. Although this is a very simple process, the image formation is not!!!\n",
    "\n",
    "In fact, the image formation depends on several factors, such as:\n",
    "\n",
    "- Light(s) within the environment\n",
    "- Surfaces properties and geometries\n",
    "- Camera optics and sensor properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09ad65a-417c-41e2-a729-4b9879421620",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"imgs/38.jpg\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2aca35-7f52-44f7-bc1d-bbbe9e2d1a3e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Light\n",
    "Actually, images cannot exists without the light. This is due to the fact that the **the devices acquire the light that is reflected by the objects**.\n",
    "As we know from Physics, the light is a wave (and also a particle 😉), so which spectrum is, for example a smartphone, acquiring with its camera?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecf7bdb-4e0c-4cfa-8256-c9591aa0a2af",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"imgs/39.jpg\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a26e0-420b-4ff1-a83e-43869f955e2e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "In addition, the intensity of a ray of light changes with the respect to the reflectance and the scattering of the hit surface, e.g., water, mirror, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50571433-5358-45de-9144-fb245cc9efaf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Digital Camera\n",
    "<img src=\"imgs/40.jpg\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279176ad-88ab-4a63-ae2d-da7d7f6d0a7f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "A digital camera, e.g., dslr, actioncam, smartphone, etc., is usually comprised of 3 \"modules\":\n",
    "- Camera body\n",
    "- Sensor\n",
    "- Image Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d4d1b9-b4a2-41fe-9695-5dff3168162f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Camera Body\n",
    "It allows to physically capture the light, and it consists of\n",
    "- Optics, also known as the lens\n",
    "- The diaphram, which allows to set the focus (and the amount of light arriving to the sensor)\n",
    "- Shutter speed, that allows to set the time used by the light to hit the sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de1f74-af16-4ad2-aed9-c56fd6ab783f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "This is how we can visualize the three components:\n",
    "\n",
    "<img src=\"imgs/41.jpg\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f10ded9-9a3e-42cc-aee6-35e1a664ceb9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "How can we use these components to  take a good picture?\n",
    "\n",
    "<img src=\"imgs/42.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9645f-924d-4e2e-91c1-951ea7770d13",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### But don't worry, your smartphone does the dirty job!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e125f6-5c4a-4548-b550-4305f5e6cdee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Sensor\n",
    "The sensor chip is the component in charge to transform the light into an image. This is done in three steps:\n",
    "- The CMOS sensor gets hit by the light\n",
    "- Some gain is applied (i.e., ISO) depending on the light in the scene. The lowest the light, the higher the ISO\n",
    "- The resulting signal is converted in a digital form with the analog to digital (ADC) converter\n",
    "\n",
    "At the end of this step, the image produce is a ***RAW*** image. This image can be intended as the digital equivalent of the *negatives*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1a42c-bb0a-4d46-a477-c27b72f3767c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"imgs/43.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5668ec75-a7cb-4821-90d8-c264b258f202",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Finally, the signal processing processor (ISP) uses some techniques on the raw image to provide a compressed image, e.g. a jpeg. These techniques may include:\n",
    "\n",
    "- White balancing\n",
    "- Denoise/Sharpen\n",
    "- Gamma/curve correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc40732e-27fc-41d8-9766-bb7105a050a6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### One Final Thing\n",
    "\n",
    "We forgot to check one last parameter: the image resolution!\n",
    "\n",
    "Let's look at a camera sensor\n",
    "\n",
    "<img src=\"imgs/44.jpg\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aebfafd-113b-47c4-97ac-53ed132896a6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "The sensor is composed of thousand on cells, namely, the pixels that will compose the image!\n",
    "\n",
    "So, the more the pixels, the more will be the resolution of the image. Notice that, the pixels on the sensor *get hit by the light*. This means that the more the resolution, the more are the pixels, and hence, the higher is the pixel number, the smaller is the size of the pixel.\n",
    "\n",
    "### SO???\n",
    "So the higher is the number of pixels, the darker will be the image since less light will hit the single pixel!\n",
    "\n",
    "This is the reason why on the smartphone the night camera has less resolution with respect to the \"normal\" camera!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d7606f-6437-4193-adde-b6a9ff307166",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    " ### Color\n",
    " Generally speaking, there are two way of \"mixing colors\": **addictive method** and **subtractive** method.\n",
    " \n",
    " <img src=\"imgs/45.jpg\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed84e9-115a-47a9-8f21-63f657434a21",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "The left image represent the addictive method. It is called addictive because we start from black, and then we subsequently add a percentage of red, green, and blue (RGB), obtaining the final color.\n",
    "\n",
    "On the other hand, the subtractive method starts from white, and when the cyan, magenta, yellow, and black (CMYK) pigments are added, they absorb certain wavelenghts and highlight others.\n",
    "\n",
    "Usually, the RGB method is used in digital images, while CYMK is used in prints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1455fc71-9ccd-4ea4-b7ba-c939c353b6d0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "At this point, we have all the elements for understanding what is an image. An image is a bi-dimensional function, defined as\n",
    "\n",
    "$$f: [0,X_{max}] \\times [0,Y_{max}] \\rightarrow [0,L_{max}] $$\n",
    "\n",
    "Subsequently, we can say that $f(x,y)$ is the *intensity* of the position $(x,y)$, $[0,X_{max}]$ is the *height* of the image, and $[0,Y_{max}]$ is the width.\n",
    "\n",
    "Then, we can consider an image as a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652de4a7-4b61-495d-a4d0-3235ef8384e8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"imgs/47.jpg\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f803028c-1e38-46af-93f3-65d31711b911",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "There are several ways to represent the intensity of a pixel:\n",
    "\n",
    "- Binary\n",
    "- Grayscale\n",
    "- Indexed\n",
    "- Color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0924bf8-6d27-4b14-bd1c-443997cffadc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Binary Images\n",
    "<img src=\"imgs/48.jpg\" width=500>\n",
    "\n",
    "- Each pixel can be black (0) or white(1)\n",
    "- It is sufficient one bit per pixel (this is not alway true)\n",
    "- Efficient in term of space occupied in memory\n",
    "- Ideal only for specific tasks, e.g. texts, fingerprints, blueprints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d275da-582a-4528-ba46-d3f9885ac814",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Grayscale Images\n",
    "<img src=\"imgs/49.jpg\" width=500>\n",
    "\n",
    "- Each pixel is a value of gray\n",
    "- Improperly called \"black and white\" images\n",
    "- Each pixel can be represented with 1 byte\n",
    "- The values are ranged between 0 (black) and 255 (white)\n",
    "- 256 color levels are sufficient to recognize most of the objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6161c877-6538-4e55-91be-712c971a7604",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Indexed Images\n",
    "<img src=\"imgs/50.jpg\" width=500>\n",
    "\n",
    "- Only few colors are used\n",
    "- The list of available colors is called *palette*\n",
    "- Some images have a well-known size of the palette, e.g. GIF has 256 colors\n",
    "- The value of the pixel is the index of the color within the palette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6ee41d-a2e4-4704-b47b-309c2831cf1f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Color Images\n",
    "<img src=\"imgs/51.jpg\" width=500>\n",
    "\n",
    "- Is the most used format of images\n",
    "- is the standard for the majority of electronic devices\n",
    "- Each pixel has an intensity for each channel, e.g. RGB\n",
    "- Each pixel ha 24 bits of information (3 byte, one byte per channel)\n",
    "- The number of color is $256^3 = 16.777.216$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf91706-23cc-4ba7-aee3-cf1a106bb558",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "So an RGB image can be seen as a 3-dimensional matrix, in which:\n",
    "\n",
    "- The number of columns is the *width* of the image\n",
    "- The number of rows is the *height* of the image\n",
    "- The depth is the *number of channels* of the image\n",
    "\n",
    "The latter could be greater than 3!!!\n",
    "\n",
    "For example, png images allow a transparent background. This information is handled through a channel, called *alpha channel*, which values are in the range $[0,1]$, where 0 means completely transparent and 1 means no transparency (e.g., a \"standard\" RGB image)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeaea11-2c99-4a97-9984-aee504a4bb7f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"imgs/46.jpg\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a57665-2499-4d8a-b969-7d8f185c5769",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Thank You\n",
    "<img src=\"imgs/thank_you.gif\" width=200>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
